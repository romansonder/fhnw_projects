{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17Eep3OWgy_bKaZ7969fcJlx5towulm5o","timestamp":1666823076110}],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["<h1>MNIST, the \"Hello World!\" of Deep Learning</h1>\n","\n","MNIST is a dataset containing tiny 28 x 28 grayscale images, each showing a handwritten digit ranging between 0 and 9. The task is to classify each image into what digit it contains and to thereby gain some experience with working with keras/tensorflow.\n","\n"],"metadata":{"id":"u7OTMAB469Fm"}},{"cell_type":"markdown","source":["**Some examples from the MNIST dataset:**\n","\n","![picture](https://drive.google.com/uc?export=view&id=1CEKDn-NpvAzabnm4prVLwk5DTLpTtM1R)"],"metadata":{"id":"0bwoKfJ--C2y"}},{"cell_type":"markdown","source":["In general, handwritten digit recognition is a real world application. The MNIST dataset is also not particularly small: it contains 60,000 images in the training set and 10,000 in the test set. Each image has a spatial dimension of 28 x 28, totaling 28²=784 features per image — a rather high dimensionality. So why is MNIST considered a “Hello World” example? As discueed during the lecture, one reason is that it is surprisingly easy to obtain a decent accuracy, around 90%, even with a weak or poorly designed machine learning model. A practical problem setting, seemingly challenging task, high accuracy with little work — a perfect combination to get started with Computer Vision using deep learning.\n","\n"],"metadata":{"id":"4N6cXTd8-Mxw"}},{"cell_type":"markdown","source":["Image classification is typically based on convolutional neural networks (CNNs)or ConvNets. ConvNets are so effective for MNIST, that even if we randomly flip the labels for most of the images in the dataset, a ConvNet can still achieve high accuracy.\n","\n","\n","> Even with 100 noisy labels for every clean label the ConvNet still attains a performance of 91%. See *Deep Learning is Robust to Massive Label Noise*, Rolnick et al.\n","\n"],"metadata":{"id":"Qkhgfw7Y-amO"}},{"cell_type":"markdown","source":["To get some exposure to deep learning using ConvNets, this exercise will walk you through the basic steps of building two \"toy\" models for classifying handwritten numbers - with accuracies surpassing 95%. The first model will be a basic fully-connected neural network, while the second model will be a deeper network that introduces the concepts of convolution and pooling. To generate, train, and evaluate your models you will use the Keras Python API with TensorFlow as the backend."],"metadata":{"id":"M34GF3JO_vN4"}},{"cell_type":"markdown","metadata":{"id":"NHKFh6Zd5fiI"},"source":["## Importing prerequisite Python modules\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I0q7zfP-5fiI"},"outputs":[],"source":["import numpy as np                  \n","import matplotlib.pyplot as plt      \n","import random                       \n","\n","from keras.datasets import mnist     # Keras includes the MNIST dataset\n","from keras.models import Sequential  # Keras model API to be used\n","\n","from keras.layers.core import Dense, Dropout, Activation  # Types of layers to be used in our models\n","from keras.utils import np_utils                          # NumPy related tools"]},{"cell_type":"markdown","metadata":{"id":"Ulm9XurM5fiJ"},"source":["## Loading the MNIST dataset\n","\n","The MNIST dataset is conveniently bundled within Keras, and we can easily analyze some of its features in Python."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7nX5ZpZ5fiK"},"outputs":[],"source":["# The MNIST data is split between 60,000 28 x 28 pixel training images \n","# and 10,000 28 x 28 pixel images\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","print(\"X_train shape\", X_train.shape)\n","print(\"y_train shape\", y_train.shape)\n","print(\"X_test shape\", X_test.shape)\n","print(\"y_test shape\", y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"Vcazs23U5fiK"},"source":["Using matplotlib, we can plot some sample images from the training set directly into this Jupyter Notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1x0i-Mdd5fiL"},"outputs":[],"source":["plt.rcParams['figure.figsize'] = (9,9) # Make the figures a bit bigger\n","\n","for i in range(9):\n","    plt.subplot(3,3,i+1)\n","    num = random.randint(0, len(X_train))\n","    plt.imshow(X_train[num], cmap='gray', interpolation='none')\n","    plt.title(\"Class {}\".format(y_train[num]))\n","    \n","plt.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"ww8N8U3e5fiL"},"source":["## Image representation\n","\n","Let's examine a single digit a bit closer, and print out the array representing the last digit."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CsljFMlV5fiL"},"outputs":[],"source":["# Just a little function to print a matrix in a pretty way\n","def matprint(mat, fmt=\"g\"):\n","    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n","    for x in mat:\n","        for i, y in enumerate(x):\n","            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n","        print(\"\")\n","    \n","matprint(X_train[num])"]},{"cell_type":"markdown","metadata":{"id":"xsxshAy85fiM"},"source":["Each pixel is an 8-bit integer ranging between 0 and 255. 0 is black, while 255 is white. This is what we call a single-channel pixel. It's called monochrome.\n","\n","*Fun-fact: Your computer screen has three channels for each pixel: red, green, blue. Each of these channels also likely takes an 8-bit integer. 3 channels -- 24 bits total -- 16,777,216 possible colors!*"]},{"cell_type":"markdown","metadata":{"id":"3_X768265fiM"},"source":["## Flattening the input data\n","\n","Instead of a 28 x 28 x 1 tensor, a fully-connected network instead requires a 784-length (feature) vector as input.\n","\n","Each image needs to be reshaped (or flattened) into a column vector. We'll also normalize the inputs to be in the range [0-1] rather than [0-255]. Normalizing inputs is generally recommended, so that any additional dimensions (for other network architectures) are of the same scale."]},{"cell_type":"markdown","source":["Example:\n","\n","![picture](https://drive.google.com/uc?export=view&id=1gNBQpPfh6y1p_yqBXe30okN-lBKp7C7E)\n"],"metadata":{"id":"TfFa3k7DE6TA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ItDqV57w5fiN"},"outputs":[],"source":["# Reshape 60,000 28 x 28 matrices into 60,000 784-length vectors\n","X_train = X_train.reshape(60000, 784)\n","# Reshape 10,000 28 x 28 matrices into 10,000 784-length vectors\n","X_test = X_test.reshape(10000, 784)   \n","\n","# Change the training and test image pixel values to be represented as \n","# 32-bit floating point numbers\n","X_train = X_train.astype('float32')   \n","X_test = X_test.astype('float32')\n","\n","# Normalize each pixel value to be between 0 and 1\n","X_train /= 255                        \n","X_test /= 255\n","\n","print(\"Training matrix shape\", X_train.shape)\n","print(\"Testing matrix shape\", X_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"3Pqq5jS65fiN"},"source":["## Converting labels to one-hot format\n","\n","We then modify our classes (unique digits) to be in the one-hot format, which simply means that each label is represented by a set of values - one value per class.\n","\n","**Examples:**\n","```\n","0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n","1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n","2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n","etc.\n","```\n","\n","The final output of our network can then be interpreted as the probability of the input belonging to each of the classes. For example, if the final output is\n","\n","```\n","[0, 0.94, 0, 0, 0, 0, 0.06, 0, 0]\n","```\n","then the input image is classified as 1 with a probability of 94%."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"elM44juH5fiN"},"outputs":[],"source":["nb_classes = 10 # number of unique digits\n","\n","Y_train = np_utils.to_categorical(y_train, nb_classes)\n","Y_test = np_utils.to_categorical(y_test, nb_classes)"]},{"cell_type":"markdown","metadata":{"id":"FQXa4t6Y2cJE"},"source":["# Building a 3-layer fully-connected network (FCN)\n","\n","We will now use Keras' sequential API to build the following fully-connected network:\n","![picture](https://drive.google.com/uc?export=view&id=19nX9IVQ1RSp0sj6srPE4IluMvZIETQzg)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"ivCRQjIa2cJE"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"YrrCMc_g2cJF"},"source":["## The first hidden layer\n","Note: You can read more on Keras sequential models here: https://keras.io/guides/sequential_model/.\n","\n","The first hidden layer is a set of 512 nodes (artificial neurons).\n","Since the model does not know the dimensions of the input images, we have to specify them for the very first layer. The activation function needs to be inserted specifically. We also add some 20% dropout probability which basically means that some random connections are dropped during training. This is one form of regularization and helps prevent the network from overfitting to the training data. We will talk more about regularization, so don't worry."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"OfmE44Mv2cJF"},"outputs":[],"source":["# The Sequential model is a linear stack of layers and operations\n","model = Sequential()\n","\n","#(784,) is not a typo -- that represents a 784 length vector\n","model.add(Dense(512, input_shape=(784,)))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.2))"]},{"cell_type":"markdown","metadata":{"id":"jDO2to6z2cJF"},"source":["## Adding the second hidden layer\n","\n","The second hidden layer is identical to our first layer. You can implement this one yourself."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"O8SUZEpK2cJG"},"outputs":[],"source":["# TODO: Add another FC layer with 512 nodes, followed by a ReLU activation \n","#       and a 20% dropout probability. In principle, it is just as above \n","#       without the need to specify the input shape to this second layer.\n","pass"]},{"cell_type":"markdown","metadata":{"id":"2omQNO202cJG"},"source":["## The output layer\n","\n","The final layer should contain as many nodes equal to the number of possible classes, which is 10 in our case. We will also use a special activation function on the final activations called the \"softmax\" activation\" which represents a probability distribution over K different possible outcomes."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"zEIyxUkS2cJG"},"outputs":[],"source":["# TODO: Add another FC layer with 10 nodes, followed by a softmax activation.\n","pass"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"JqFiyFk72cJG"},"outputs":[],"source":["# Summarize the built model\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"oiXpNN5g2cJG"},"source":["## Compiling the model\n","\n","Keras is built on top of TensorFlow which allows you to define a *computation graph* in Python, which then compiles and runs efficiently on the CPU or GPU without the overhead of the Python interpreter. When compiing a model, Keras asks you to specify your **loss function** and your **optimizer**. \n","\n","The loss function we'll use here is called *categorical cross-entropy*, which is well-suited to comparing two probability distributions. Our predictions are probability distributions across the ten different digits (e.g. \"we're 80% confident this image is a 3, 10% sure it's an 8, 5% sure it's a 2, and so on\"), and the image label (in one-hot format!) is a probability distribution with 100% for the correct category, and 0% for everything else. The cross-entropy is a measure of how different is your predicted distribution from the target distribution. [Cross Entropy](https://en.wikipedia.org/wiki/Cross_entropy)\n","\n","The optimizer helps determine how quickly the model learns through **gradient descent**. The **learning rate** determines how harshly the weights are adjusted during each training iteration (i.e. the rate at which the weights decend along the gradients)."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"iyPVI1xG2cJH"},"outputs":[],"source":["# Using the adam optimizer is a very standard choice and always a good starting point\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"5Hw2B1je2cJH"},"source":["## Train the model\n","This is the fun part! \n","\n","The batch size determines over how much data is used per step to compute the loss function, gradients, and back propagation. Large batch sizes allow for faster training; however, there are other factors beyond training speed to consider.\n","\n","A batch size that is too large smoothes the local minima of the loss function, causing the optimizer to get stuck in a local optimum.\n","A batch size that is too small results in a very noisy loss value, and the optimizer may never find the global optimum.\n","\n","So, it may take some trial and error to find a good batch size."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HxzYEEDC2cJI"},"outputs":[],"source":["model.fit(X_train, Y_train,\n","          batch_size=128, epochs=5,\n","          verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"Nx4-eh3N2cJI"},"source":["The two numbers, in order, represent the value of the loss function of the network on the training set, and the overall accuracy of the network on the training data. But how does it do on data it did not train on?"]},{"cell_type":"markdown","metadata":{"id":"P64jx-X22cJI"},"source":["## Evaluate the model on the test data\n","\n","This is the exciting (and sometimes also nerve-wracking) part!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uAoo9of92cJI"},"outputs":[],"source":["score = model.evaluate(X_test, Y_test)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"]},{"cell_type":"markdown","metadata":{"id":"UcNTRSZL2cJI"},"source":["### Inspecting the output\n","\n","It's always a good idea to inspect the output and make sure everything looks sane. Here, we'll look at some examples for which the model predicts the correct class/digit, and at some examples or which the model predicts the incorrect class/digit."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"PfpIj-5c2cJI"},"outputs":[],"source":["# The predict function outputs the probability per class for each \n","# input example using our trained classifier.\n","predicted_classes = np.argmax(model.predict(X_test), axis=1)\n","\n","# Check which items we got right / wrong\n","correct_indices = np.nonzero(predicted_classes == y_test)[0]\n","incorrect_indices = np.nonzero(predicted_classes != y_test)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUVe8nl-2cJJ"},"outputs":[],"source":["plt.figure()\n","for i, correct in enumerate(correct_indices[:9]):\n","    plt.subplot(3,3,i+1)\n","    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n","    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_test[correct]))\n","    \n","plt.tight_layout()\n","    \n","plt.figure()\n","for i, incorrect in enumerate(incorrect_indices[:9]):\n","    plt.subplot(3,3,i+1)\n","    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n","    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_test[incorrect]))\n","    \n","plt.tight_layout()"]},{"cell_type":"markdown","source":["Some of this misclassifications kind of make sense, right?"],"metadata":{"id":"nbtjqAB6Xa8J"}},{"cell_type":"markdown","metadata":{"id":"GbxWh5_q2cJJ"},"source":["# Trying experimenting with the batch size!\n","\n","1.   How does increasing the batch size to 10,000 affect the training time and test accuracy?\n","2.   How about a batch size of 32?\n"]},{"cell_type":"markdown","metadata":{"id":"LAbpEaBT2cJK"},"source":["## Building a Convolutional Neural Network (CNN)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"SC1Ds0b22cJK"},"outputs":[],"source":["# Import some additional tools\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n","from tensorflow.keras.layers import BatchNormalization"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"CcJuXxAp2cJK"},"outputs":[],"source":["# Reload the MNIST dataset\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3xleB08I2cJK"},"outputs":[],"source":["# Again, apply some formatting but we do not need to flatten the images this time. \n","# Remember that convolutions directly receive images and preserve their spatial structure.\n","\n","# Add an additional dimension to represent the depth (which is 1 for grayscale images)\n","X_train = X_train.reshape(60000, 28, 28, 1) \n","X_test = X_test.reshape(10000, 28, 28, 1)\n","\n","X_train = X_train.astype('float32')        \n","X_test = X_test.astype('float32')\n","\n","X_train /= 255\n","X_test /= 255\n","\n","print(\"Training matrix shape\", X_train.shape)\n","print(\"Testing matrix shape\", X_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"EYzxuFQ62cJL"},"outputs":[],"source":["# One-hot format classes as before\n","nb_classes = 10\n","\n","Y_train = np_utils.to_categorical(y_train, nb_classes)\n","Y_test = np_utils.to_categorical(y_test, nb_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"XEoGU9hy2cJL"},"outputs":[],"source":["model = Sequential()                                 # Linear stacking of layers\n","\n","# Convolution Layer 1\n","# The first conv layer will use 32 different 3x3 filters. And again, since \n","# the model cannot know the size of the input images, we specify them explicitly \n","# just for this first layer. We also use batch normalization which normalizes \n","# each feature map before applying the activation function. We will talk more \n","# about batch normalization.\n","model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n","model.add(BatchNormalization(axis=-1))            \n","model.add(Activation('relu'))\n","\n","# Convolution Layer 2\n","# TODO: Add a second conv layer with 32 3x3 filters. Also add a batch norm \n","# layer and a ReLU activation just as for the first layer.\n","pass                       \n","\n","# Pooling Layer\n","# Next, we insert a max pooling layer using a 2x2 filter.\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","# Convolution Layer 3\n","# TODO: Add a third conv layer with 64 3x3 filters. Also add a batch norm \n","# layer and a ReLU activation just as for the first two layers.\n","pass  \n","\n","# Convolution Layer 4\n","# TODO: Add a third conv layer with 64 3x3 filters. Also add a batch norm \n","# layer and a ReLU activation followed by a 2x2 max pooling layer.\n","pass\n","\n","# The final two layer will be fully-connected layer so we need to flatten \n","# the 3-dim tensor output by the 4th conv layer into a 1024-element vector.\n","model.add(Flatten())\n","\n","# Fully Connected Layer 5\n","# TODO: Add a FC layer with 512 nodes. Also add a batch norm layer (just use \n","# BatchNormalization() without specifying the axis), a ReLU activation, and a \n","# 20% dropout layer (as used in the FC network above).\n","pass                         \n","\n","# Fully Connected Layer 6\n","# TODO: Add the output FC layer with 10 nodes which needs to be followed by a \n","# softmax activation as discussed above.\n","pass                                      "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vciu5wjt2cJL"},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"P2y1xvnp2cJL"},"outputs":[],"source":["# We will use the same loss and optimizer as for the FC network\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"8VGFeIl92cJL"},"outputs":[],"source":["# Data augmentation prevents overfitting by slightly changing the input data.\n","# Keras has a great API to perform automatic image augmentation.\n","\n","train_gen = ImageDataGenerator(\n","    rotation_range=8, width_shift_range=0.08, shear_range=0.3, \n","    height_shift_range=0.08, zoom_range=0.08)\n","\n","test_gen = ImageDataGenerator()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"tJGC8kGF2cJL"},"outputs":[],"source":["# This also allows us to feed our augmented data batches more efficiently. \n","# Besides loss function considerations, as discussed above, using this method \n","# actually results in significant memory savings because we are actually \n","# also LOADING the data in batches into memory (and directly process the batch).\n","# This is particularly important when training larger and deeper networks on \n","# huge amounts of data. Before, all of the data was loaded into memory, and \n","# then only  processed in batches.\n","\n","train_generator = train_gen.flow(X_train, Y_train, batch_size=128)\n","test_generator = test_gen.flow(X_test, Y_test, batch_size=128)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-nd1-f52cJM"},"outputs":[],"source":["# We can now train our model by feeding it data using our batch loader.\n","# Steps per epoch should always be equal to the total size of the training set \n","# divided by the batch size.\n","model.fit_generator(\n","    train_generator, steps_per_epoch=60000//128, epochs=5, verbose=1,\n","    validation_data=test_generator, validation_steps=10000//128)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hAcNenay2cJM"},"outputs":[],"source":["score = model.evaluate(X_test, Y_test)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"]},{"cell_type":"markdown","source":["As previously mentioned, recognizing the handwritten digits contained in MNIST is not that challenging anymore and we obtain fairly similar accuracy using either a FC network or a CONV network."],"metadata":{"id":"Z2MQliXmZ25R"}}]}